# Awesome-segment-anything-model :octocat:

<img src="https://github.com/ChaoningZhang/Awesome-segment-anything-model/blob/main/fig/masks2.jpg" width="600" height="400" alt="Segment Anything" />

**Original paper link:https://ai.facebook.com/research/publications/segment-anything/**

**Original repo link:https://github.com/facebookresearch/segment-anything**

# Recent Papers

* [Brain Extraction comparing Segment Anything Model (SAM) and FSL Brain Extraction Tool](https://arxiv.org/pdf/2304.04738.pdf)(2023/04/15)

This paper compares the Segment Anything Model (SAM) with FSL's Brain Extraction Tool (BET) for brain extraction on different brain scans. Results show that SAM outperforms BET in various evaluation parameters, especially with signal inhomogeneities, non-isotropic voxel resolutions, or lesions near the brain's outer regions and meninges. SAM's superior performance suggests its potential as a more accurate, robust, and versatile tool for brain extraction and segmentation applications.

<img src="https://github.com/ChaoningZhang/Awesome-segment-anything-model/blob/main/fig/IIXSUPR%24(V4%60EXXTKZ3EO%7B3.png" width="550" height="400" alt="Segment Anything" />

* [SAM Struggles in Concealed Scenes--Empirical Study on" Segment Anything"](https://arxiv.org/pdf/2304.06022.pdf)(2023/04/15)

In this report, three concealed scenes (camouflaged animals, industrial defects, and medical lesions) have been tested to evaluate SAM's performance under unprompted settings. The main observation is that SAM struggles to accurately identify objects in these scenes.

<img src="https://github.com/ChaoningZhang/Awesome-segment-anything-model/blob/main/fig/HAAC32DMHSH(M_NQ87EDK%7B8.png" width="780" height="400" alt="Segment Anything" />

* [Segment Anything Is Not Always Perfect: An Investigation of SAM on Different Real-world Applications](https://arxiv.org/pdf/2304.05750.pdf)(2023/04/13)

This work investigates the performance of the Segment Anything Model (SAM) pre-trained on SA-1B across various applications, such as natural images, agriculture, manufacturing, remote sensing, and healthcare. The benefits and limitations of SAM are analyzed and discussed, with an outlook on future development of segmentation tasks. This provides a comprehensive view of SAM in practice, which will facilitate future research activities.

<img src="https://github.com/ChaoningZhang/Awesome-segment-anything-model/blob/main/fig/J%40%5B_6Z6DP7GI8QYI%7D%60PHMKD.png" width="780" height="400" alt="Segment Anything" />

* [SAMM (Segment Any Medical Model): A 3D Slicer Integration to SAM](https://arxiv.org/pdf/2304.05622.pdf)(2023/04/12)

This paper introduces the Segment Any Medical Model (SAMM), a 3D Slicer extension of the Segment Anything Model (SAM) for medical image segmentation. SAMM has demonstrated good promptability and generalizability and can infer masks in nearly real-time with 0.6-second latency. The open-source SAMM and its demonstrations are available on GitHub.

<img src="https://github.com/ChaoningZhang/Awesome-segment-anything-model/blob/main/fig/504(G3LC1C)%24%602ASDTIKONC.png" width="780" height="400" alt="Segment Anything" />

* [Can SAM Segment Anything? When SAM Meets Camouflaged Object Detection](https://arxiv.org/pdf/2304.04709)(2023/04/11)

This paper investigates how well SAM performs in the task of Camouflaged Object Detection (COD) and compares SAM's performance to 22 state-of-the-art COD methods. 

<img src="https://github.com/ChaoningZhang/Awesome-segment-anything-model/blob/main/fig/9GCIT)PHA%5BU%25HEEE%60Y0B%7D_8.png" width="780" height="400" alt="Segment Anything" />

* [Segmenting Anything Also Detect Anything](https://wwwww.easychair.org/publications/preprint_download/HVhP)(2023/04/10)

This paper proposes the use of computer vision macromodels (SAMs) to guide semi-automated annotation of data in the domain of specific object detection, and the High Fine Grain Fill-in Augmentation (HFGFA) method for visual image data augmentation. These approaches have been shown to improve model generalisation and open world object detection capabilities.

<img src="https://github.com/ChaoningZhang/Awesome-segment-anything-model/blob/main/fig/~IA%5DE%7D08%5D(%24WKHYF535IRSX.png" width="780" height="400" alt="Segment Anything" />

* [Segment Anything Model (SAM) for Digital Pathology: Assess Zero-shot Segmentation on Whole Slide Imaging](https://arxiv.org/pdf/2304.04155.pdf)(2023/04/09)

This study evaluates the SAM model's performance on whole slide imaging (WSI) tasks such as tumor segmentation, non-tumor tissue segmentation, and cell nuclei segmentation. The results suggest that the model performs well for large objects, but does not consistently perform well for dense instance object segmentation. Identified limitations for digital pathology include image resolution, multiple scales, prompt selection, and model fine-tuning. Future work should explore few-shot fine-tuning with images from downstream pathological segmentation tasks to improve performance.

<img src="https://github.com/ChaoningZhang/Awesome-segment-anything-model/blob/main/fig/E54BTV%40K3Q3O%40%25K8%7DW1%5DQ%7BP.png" width="780" height="400" alt="Segment Anything" />

# Recent Projects

* [Grounded-Segment-Anything](https://github.com/IDEA-Research/Grounded-Segment-Anything#grounded-segment-anything)
* [GroundedSAM-zero-shot-anomaly-detection](https://github.com/caoyunkang/GroundedSAM-zero-shot-anomaly-detection)
* [Segment and Track Anything (SAM-Track)](https://github.com/z-x-yang/Segment-and-Track-Anything)
* [SEEM: Segment Everything Everywhere All at Once](https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once)
* [IEA: Image Editing Anything](https://github.com/feizc/IEA)
* [Semantic Segment Anything (SSA)](https://github.com/fudan-zvg/Semantic-Segment-Anything)
* [Segment Anything with Clip](https://github.com/Curt-Park/segment-anything-with-clip)
* [Magic Copy](https://github.com/kevmo314/magic-copy)
* [Edit Anything by Segment-Anything](https://github.com/sail-sg/EditAnything)
* [Prompt-Segment-Anything](https://github.com/RockeyCoss/Prompt-Segment-Anything)
* [SAM-RBox](https://github.com/Li-Qingyun/sam-mmrotate)
* [Segment-anything-with-image-captioning](https://github.com/bnabis93/segment-anything-image-search)
* [Open-vocabulary-Segment-Anything](https://github.com/ngthanhtin/owlvit_segment_anything)
* [SegDrawer](https://github.com/lujiazho/SegDrawer)
* [Label-Anything-Pipeline](https://github.com/Yuqifan1117/Labal-Anything-Pipeline)
* [MOTRv2: Bootstrapping End-to-End Multi-Object Tracking by Pretrained Object Detectors](https://github.com/BingfengYan/VISAM)
* [Segment Anything Model (SAM) in Napari](https://github.com/MIC-DKFZ/napari-sam)
* [Inpaint Anything: Segment Anything Meets Image Inpainting](https://github.com/geekyutao/Inpaint-Anything)
* [Segment Anything EO tools](https://github.com/aliaksandr960/segment-anything-eo)
* [napari-segment-anything](https://github.com/JoOkuma/napari-segment-anything)
* [Grounded Segment Anything: From Objects to Parts](https://github.com/Cheems-Seminar/grounded-segment-any-parts)
* [AnyLabeling](https://github.com/vietanhdev/anylabeling)
* [Caption-Anything](https://github.com/ttengwang/Caption-Anything)
* [Segment-Anything-U-Specify](https://github.com/MaybeShewill-CV/segment-anything-u-specify)
* [Optical Character Recognition with Segment Anything (OCR-SAM)](https://github.com/yeungchenwa/OCR-SAM)
* [grounded-segment-anything-colab](https://github.com/camenduru/grounded-segment-anything-colab)
* [SAM Medical Imaging](https://github.com/amine0110/SAM-Medical-Imaging)
* [Image.txt: Transform Image Into Unique Paragraph](https://github.com/showlab/Image2Paragraph)
* [LIME-SAM](https://github.com/jaydeep-work/LIME-SAM)
* [A simple demo for SAM+MMDetection](https://github.com/liuyanyi/sam-with-mmdet)
* [3D-Box via Segment Anything](https://github.com/dvlab-research/3D-Box-Segment-Anything)
* [Anything-3D](https://github.com/Anything-of-anything/Anything-3D)
* [Transfer-Any-Style](https://github.com/Anything-of-anything/Transfer-Any-Style)
* [Paint-Anything](https://github.com/Huage001/Paint-Anything)
* [Track-Anything](https://github.com/gaomingqi/Track-Anything)
